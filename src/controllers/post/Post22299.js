export const Post22299 = () => {
    return (
        <div className="w-full text-left">
            <div className="w-full min-h-[400px] md:min-h-[500px] rounded-xl" style={{background: `url(/blog-photos/Charlee.ai-and-Reducing-Bias-in-Artificial-Intelligence-–-Part-2-head-image.webp)`, backgroundSize: 'cover', backgroundPosition: 'center', backgroundRepeat: 'no-repeat' }}></div>
            
            <p className="mt-4">Charlee.ai and Reducing Bias in Artificial Intelligence – Part 2</p>
            <p className="mt-4">In <a href="https://charlee.ai/charlee-ai-and-reducing-bias-in-artificial-intelligence-part-1/">part 1</a> of this 2 part series we examined how bias is fundamentally ingrained into any kind of technology or processes built by humans. Recognizing and working with it in every decision we take is the only way to address and minimize its influence on our business processes. A conscious approach to understanding and addressing bias begins from incorporating compliance and risk concerns into every aspect of the insurance process, from data handling and risk assessment to decision systems and stakeholder education. Insurers should continuously evaluate system performance, know when problems of bias arise, pre-empt and prepare to deal with them and configure steps to identify and course correct where necessary.</p>
            <p className="mt-4">Among the foremost factors that can affect the creeping of bias into existing business systems, is the role of regulation and compliance and the changes that are constantly being introduced into the regulatory landscape. Committing to fairness and transparency across the organization is a corporate responsibility. Managing AI risks like bias is a business and not just a technical or technological problem.</p>
            
            <div className="w-full min-h-[400px] md:min-h-[500px] rounded-xl" style={{background: `url(/blog-photos/Charlee.ai-and-Reducing-Bias-in-Artificial-Intelligence-–-Part-2-Prevention-of-Bias-in-AI-Large-Language-Models.webp)`, backgroundSize: 'contain', backgroundPosition: 'center', backgroundRepeat: 'no-repeat' }}></div>
            
            <h3 className="mt-4 text-[22px] font-bold">The Current Regulatory Landscape</h3>
            <p className="mt-4">In December 2023, the National Association of Insurance Commissioners (NAIC) published a Model Bulletin for regulating AI used by insurance companies <a href="#_ftn1" name="_ftnref1">[1]</a>. To date, thirteen states have enacted regulations for the use of AI by insurance companies. Charlee.ai contributed to developing and promulgating the Bulletin by providing training and expertise to the AI, Innovation, Big Data committees and various state insurance departments. Charlee.ai continues to work with the NAIC committees and regulators to provide technology and domain expertise for AI in insurance workflows.</p>
            <p className="mt-4"><a href="#_ftnref1" name="_ftn1">[1]</a> <a href="https://content.naic.org/sites/default/files/inline-files/2023-12-4%20Model%20Bulletin_Adopted_0.pdf">https://content.naic.org/sites/default/files/inline-files/2023-12-4%20Model%20Bulletin_Adopted_0.pdf</a></p>
            
            <h3 className="mt-4 text-[22px] font-bold">Standards that Define Charlee’s Prevention of Bias in AI Large Language Models</h3>
            <p className="mt-4">Insurance and trust being fundamentally interwoven, ensuring fairness and transparency in using AI platforms, is a corporate responsibility that must be adhered to at all times. Charlee™ has developed a set of techniques and standards for ensuring buyers’ trust, and monitoring the element of bias that may creep in anywhere during the AI intervention cycle. Below are a few critical insights from our thought leadership about the AI platform one chooses to use.</p>
            
            <div className="w-full min-h-[400px] md:min-h-[500px] rounded-xl" style={{background: `url(/blog-photos/Charlee.ai-and-Reducing-Bias-in-Artificial-Intelligence-–-Part-2-Stakeholder-Collaboration-in-Eliminating-Bias.webp)`, backgroundSize: 'contain', backgroundPosition: 'center', backgroundRepeat: 'no-repeat' }}></div>
            
            <h3 className="mt-4 text-[22px] font-bold">Role of Stakeholder Collaboration in Eliminating Bias</h3>
            <p className="mt-4">The insurance ecosystem is built around a siloed framework where essential stakeholders are separated from one another based on their primary tasks, decision-making abilities, and depth of expertise. Human nature is prone to prejudice, which can creep into decision-making at any time. Similarly, in AI and other consequential decision systems, the technical nature of the work breaks it into siloes. Data scientists and engineers develop the systems, risk and compliance teams later evaluate them, and every stakeholder does it separately, owing to which bias can enter the system unknowingly.</p>
            <p className="mt-4">To combat this, it is critical for all stakeholders and technical and subject matter experts to work together with trust and transparency built into the order of work. Human processes and decisions surrounding the language model’s conception, development, and deployment have to come together to understand the goal, arrive at expected outcomes, and reason the model’s best possible solution for the business problem that must be addressed. Once the language and ML models are adopted, non-technical members need to find user-friendly ways to monitor, access, and understand the decisions made by the AI. Insurers must continuously evaluate system performance, know when biases arise, and address them efficiently, correcting course as needed.</p>
            
            <h3 className="mt-4 text-[22px] font-bold">How Charlee.ai Models Have Been Developed to Minimize Bias</h3>
            <p className="mt-4">The Charlee AI platform is built within the regulatory compliance framework and overseen by insurance experts. It provides pre-trained models for AI-based claims analytics, including severity, litigation, attorney involvement predictions, and fraud indicators.</p>
            <p className="mt-4">1. <strong>Model inputs:</strong> Charlee severity, litigation, and suspicious claims models have been developed in close collaboration with domain experts who have vetted the models at every stage. Domain experts have helped define the model inputs and the ontologies that help train Charlee’s NLP models. We have carefully selected columns that capture the injury and damage severity, as well as behavioral patterns that are independent of the group (race, gender, etc.) that the claimant belongs to.</p>
            <p className="mt-4">2. <strong>Testing for bias:</strong> Charlee models are regularly and carefully tested with domain experts to prevent bias from creeping in. The model prediction distribution is weighed against the input data to ensure it is fair.</p>
            <p className="mt-4">3. <strong>Expert reviews:</strong> Our business analysts and data scientists carefully select a good distribution of anomalous and statistically conformant claims for review by domain experts. Our domain experts review the selected claims in detail and validate the predictions. Any issues they point out are promptly investigated.</p>
            <p className="mt-4">4. <strong>Guard rails:</strong> Charlee employs a library of models based on LOB and coverage. Domain expert inputs are used to define guard rails for the predictions. Models are carefully selected, and an ensemble is configured to ensure compliance.</p>
            
            <h3 className="mt-4 text-[22px] font-bold">Conclusion</h3>
            <p className="mt-4">Bias can creep into AI models in various ways. Having an objective oversight and risk controls are best practices to follow when analyzing data models. Careful selection of model inputs, thorough tuning and testing, and close collaboration between domain experts, business analysts, and data scientists can help reduce model bias in AI. While it is human nature to be biased, insurers can do well to implement transparency, risk governance and objectivity with a clear intent to do the right thing.</p>
            <p className="mt-4">That’s why at Charlee.AI, we have defined, and employ these best practices that ensure compliance of our AI models.</p>
            
            <h3 className="mt-4 text-[22px] font-bold">Request a Demo:</h3>
            <form action="https://charlee.ai/charlee-ai-and-reducing-bias-in-artificial-intelligence-part-2/" method="post" className="mt-4">
                <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                    <div>
                        <label htmlFor="firstname" className="block">First Name <abbr title="required">*</abbr></label>
                        <input type="text" name="firstname" id="firstname" className="w-full border rounded p-2" required placeholder="First Name *" />
                    </div>
                    <div>
                        <label htmlFor="lastname" className="block">Last Name <abbr title="required">*</abbr></label>
                        <input type="text" name="lastname" id="lastname" className="w-full border rounded p-2" required placeholder="Last Name *" />
                    </div>
                    <div>
                        <label htmlFor="phone_number" className="block">Phone Number</label>
                        <input type="tel" name="phone_number" id="phone_number" className="w-full border rounded p-2" placeholder="888-888-8888" />
                    </div>
                    <div>
                        <label htmlFor="email" className="block">Email <abbr title="required">*</abbr></label>
                        <input type="email" name="email" id="email" className="w-full border rounded p-2" required placeholder="@email *" />
                    </div>
                </div>
                <div className="mt-4">
                    <p>I would like to:</p>
                    <div className="flex flex-col">
                        <label>
                            <input type="checkbox" name="product[]" value="Learn more about the Free POC *" className="mr-2" />
                            Learn more about the Free POC *
                        </label>
                        <label>
                            <input type="checkbox" name="product[]" value="Receive Product Information" className="mr-2" />
                            Receive Product Information
                        </label>
                        <label>
                            <input type="checkbox" name="product[]" value="Request a Demo" className="mr-2" />
                            Request a Demo
                        </label>
                        <label>
                            <input type="checkbox" name="product[]" value="Receive your Whitepaper" className="mr-2" />
                            Receive your Whitepaper
                        </label>
                    </div>
                </div>
                <div className="mt-4 text-right">
                    <button type="submit" className="bg-teal-500 text-white py-2 px-4 rounded">Submit</button>
                </div>
            </form>
        </div>
    );
};
